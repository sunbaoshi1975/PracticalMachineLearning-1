library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
t1 <- factor(vowel.train)
training <- vowel.train
training <- vowel.train
testing <- vowel.test
set.seed(33833)
model_rf <- traing(y~., data=training, method="rf")
model_rf <- train(y~., data=training, method="rf")
library(caret)
model_rf <- train(y~., data=training, method="rf")
model_gbm <- train(y~., data=training, method="gbm")
pred_rf <- predict(model_df, testing)
pred_rf <- predict(model_rf, testing)
pred_gbm <- predict(model_gbm, testing)
training <- vowel.train
testing <- vowel.test
set.seed(33833)
library(caret)
model_rf <- train(y~., data=training, method="rf")
training <- vowel.train
testing <- vowel.test
set.seed(33833)
library(caret)
model_rf <- train(y~., data=training, method="rf")
pred_rf <- predict(model_rf, testing)
model_gbm <- train(y~., data=training, method="gbm")
pred_gbm <- predict(model_gbm, testing)
confusionMatrix(pred_rf, testing$y)$overall
confusionMatrix(pred_gbm, testing$y)$overall
pred_rf
testing$y
?confusionMatrix
?round
round(2.6)
round(2.6)
round(2.5)
pred_rf <- round(predict(model_rf, testing))
pred_gbm <- round(predict(model_gbm, testing))
confusionMatrix(pred_rf, testing$y)$overall
pred_rf
testing$y
?predict
confusionMatrix(pred_gbm,pred_rf)
pred_rf <- predict(model_rf,testing, type="class")
View(vowel.test)
View(vowel.test)
class(vowel.test$y)
confusionMatrix(pred_rf, as.factor(testing$y))$overall
sum(pred_rf==testing$y)
dim(testing)
length(testing)
row(testing)
dim(testing)[1]
sum(pred_rf == testing$y)/dim(testing)[1]
sum(pred_gbm==testing$y)/dim(testing)[1]
sum(pred_rf==pred_gbm)/dim(testing)[1]
training <- vowel.train
testing <- vowel.test
vowel.test$y <- as.factor(vowel.test$y)
vowel.train$y <- as.factor(vowel.train$y)
set.seed(33833)
library(caret)
model_rf <- train(y~., data=training, method="rf")
model_gbm <- train(y~., data=training, method="gbm")
pred_rf <- predict(model_rf,testing,prox = TRUE)
pred_gbm <- round(predict(model_gbm, testing))
sum(pred_rf == testing$y)/dim(testing)[1]
sum(pred_gbm==testing$y)/dim(testing)[1]
sum(pred_rf==pred_gbm)/dim(testing)[1]
model_rf <- randomForest(y~., data=training)
pred_rf <- predict(model_rf,testing)
sum(pred_rf == testing$y)/dim(testing)[1]
pred_rf <- round(predict(model_rf,testing))
sum(pred_rf == testing$y)/dim(testing)[1]
?randomForest
pred_rf
model_rf <- train(y~., data=vowel.train, method="rf")
model_rf <- randomForest(y~., data=vowel.train)
pred_rf <- round(predict(model_rf,testing))
pred_rf <- predict(model_rf,testing)
sum(pred_rf == testing$y)/dim(testing)[1]
model_rf <- train(y~., data=vowel.train, method="rf")
model_rf <- randomForest(y~., data=vowel.train)
pred_rf <- predict(model_rf,vowel.test)
sum(pred_rf == testing$y)/dim(testing)[1]
model_rf <- train(y~., data=vowel.train, method="rf")
pred_rf <- predict(model_rf,vowel.test)
sum(pred_rf == testing$y)/dim(testing)[1]
confusionMatrix(pred_rf, vowel.test)
sum(pred_rf == vowel.test$y)/dim(testing)[1]
sum(pred_rf == vowel.test$y)/dim(vowel.test)[1]
pred_rf
vowel.test$y
vowel.test$y <- as.factor(vowel.test$y)
vowel.train$y <- as.factor(vowel.train$y)
library(caret)
set.seed(33833)
model_rf <- train(y~., data=vowel.train, method="rf")
model_gbm <- train(y~., data=vowel.train, method="gbm")
pred_rf <- predict(model_rf,vowel.test)
pred_gbm <- predict(model_gbm,vowel.test)
sum(pred_rf == vowel.test$y)/dim(vowel.test)[1]
sum(pred_gbm==vowel.test)/dim(vowel.test)[1]
sum(pred_rf==pred_gbm)/dim(vowel.test)[1]
sum(pred_gbm==vowel.test$y)/dim(vowel.test)[1]
sum(pred_rf==pred_gbm)/dim(vowel.test)[1]
library(caret)
library(gbm)
set.seed(3433)
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
library(caret)
library(gbm)
set.seed(3433)
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
set.seed(62433)
model_rf <- train(diagnosis~., data=training,method="rf")
model_gbm <- train(diagnosis~., data=training, method="gbm")
model_lda <- train(diagnosis~., data=training,method="lda")
pred_train_rf <- predict(model_rf,training)
pred_train_gbm <- predict(model_gbm,training)
pred_train_lda <- predict(model_lda, training)
pred_train_lda
pred_train_rf
training_combi <- data.fram(diagnosis=training$diagnosis,rf=pred_train_rf,gbm=pred_train_gbm,lda=pred_train_lda)
training_combi <- data.frame(diagnosis=training$diagnosis,rf=pred_train_rf,gbm=pred_train_gbm,lda=pred_train_lda)
View(training_combi)
View(training_combi)
accuracy <- function(x,y){
return(sum(x==y)/dim(y)[1])
}
accurancy(pred_rf,training$diagnosis)
```
accuracy(pred_rf,training$diagnosis)
pred_rf <- predict(model_rf,training)
pred_gbm <- predict(model_gbm,training)
pred_lda <- predict(model_lda, training)
p
accuracy(pred_rf,training$diagnosis)
pred_rf
training$diagnosis
sum(pred_rf==training$diagnosis)
dim(training$diagnosis)
count(training$diagnosis)
sum(training$diagnosis)
sum(training$diagnosis!=NA)
sum(training$diagnosis != NA)
count(training$diagnosis!=NA)
accuracy <- function(x,y){
return(sum(x==y)/count(y!=NA))
}
accuracy(pred_rf,training$diagnosis)
dim(training$diagnosis)
length(training$diagnosis)
accuracy <- function(x,y){
return(sum(x==y)/length(y))
}
accuracy(pred_rf,training$diagnosis)
?format
percent(0.1)
library('scales')
percent(0.1)
library('scales')
accuracy <- function(x,y){
return(precent(sum(x==y)/length(y)))
}
accuracy(pred_rf,training$diagnosis)
library('scales')
accuracy <- function(x,y){
return(percent(sum(x==y)/length(y)))
}
accuracy(pred_rf,training$diagnosis)
train_pred_rf <- predict(model_rf,training)
train_pred_gbm <- predict(model_gbm,training)
train_pred_lda <- predict(model_lda, training)
accuracy(train_pred_rf,training$diagnosis)
accuracy(train_pred_gbm,training$diagnosis)
accuracy(train_pred_lda,training$diagnosis)
set.seed(62433)
model_rf <- train(diagnosis~., data=training,method="rf")
model_gbm <- train(diagnosis~., data=training, method="gbm")
model_lda <- train(diagnosis~., data=training,method="lda")
pred_rf <- predict(model_rf,testing)
pred_gbm <- predict(model_gbm,testing)
pred_lda <- predict(model_lda, testing)
pred_combi <- data.frame(diagnosis=testing$diagnosis,rf=pred_rf,gbm=pred_gbm,lda=pred_lda)
model_final <- train(diagnosis~., data=pred_combi, method="rf")
pred_final <- predict(model_final,testing)
model_final
pred_final
pred_final <- predict(model_final,testing)
pred_combi
accuracy(pred_rf,testing$diagnosis)
accuracy(pred_gbm,testing$diagnosis)
accuracy(pred_lda,testing$diagnosis)
accuracy(pred_model,testing$diagnosis)
accuracy(pred_final,testing$diagnosis)
pred_final <- predict(model_final,testing)
pred_combi <- data.frame(diagnosis=testing$diagnosis,rf=pred_rf,gbm=pred_gbm,lda=pred_lda)
model_final <- train(diagnosis~., data=pred_combi, method="rf")
pred_final <- predict(model_final,testing)
View(pred_combi)
View(pred_combi)
class(training)
View(training)
model_final <- train(diagnosis~., data=pred_combi, method="rf")
model_final
pred_final <- predict(model_final,testing)
pred_final <- predict(model_final,pred_combi)
accuracy(pred_rf,testing$diagnosis)
accuracy(pred_gbm,testing$diagnosis)
accuracy(pred_lda,testing$diagnosis)
accuracy(pred_final,testing$diagnosis)
set.seed(62433)
model_rf <- train(diagnosis~., data=training,method="rf")
model_gbm <- train(diagnosis~., data=training, method="gbm")
model_lda <- train(diagnosis~., data=training,method="lda")
pred_rf <- predict(model_rf,testing)
pred_gbm <- predict(model_gbm,testing)
pred_lda <- predict(model_lda, testing)
pred_combi <- data.frame(diagnosis=testing$diagnosis,rf=pred_rf,gbm=pred_gbm,lda=pred_lda)
model_final <- train(diagnosis~., data=pred_combi, method="rf")
pred_final <- predict(model_final,pred_combi)
library('scales')
accuracy <- function(x,y){
return(percent(sum(x==y)/length(y)))
}
accuracy(pred_rf,testing$diagnosis)
accuracy(pred_gbm,testing$diagnosis)
accuracy(pred_lda,testing$diagnosis)
accuracy(pred_final,testing$diagnosis)
model_gbm <- train(diagnosis~., data=training, method="gbm",verbose=F)
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
library(caret)
library(gbm)
set.seed(3433)
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
set.seed(62433)
model_rf <- train(diagnosis~., data=training,method="rf")
model_gbm <- train(diagnosis~., data=training, method="gbm",verbose=F)
model_lda <- train(diagnosis~., data=training,method="lda")
training_pred_rf <- predict(model_rf,training)
training_pred_gbm <- predict(model_gbm,training)
training_pred_lda <- predict(model_lda, training)
df_combi <- data.frame(diagnosis=testing$diagnosis,rf=training_pred_rf,gbm=training_pred_gbm,lda=training_pred_lda)
model_final <- train(diagnosis~., data=df_combi, method="rf")
pred_rf <- predict(model_rf,testing)
pred_gbm <- predict(model_gbm, testing)
pred_lda <- predict(model_lda, testing)
pred_final <- predict(model_final,pred_combi)
library('scales')
accuracy <- function(x,y){
return(percent(sum(x==y)/length(y)))
}
accuracy(pred_rf,testing$diagnosis)
accuracy(pred_gbm,testing$diagnosis)
accuracy(pred_lda,testing$diagnosis)
accuracy(pred_final,testing$diagnosis)
pred_final <- predict(model_final,pred_combi)
model_final <- train(diagnosis~., data=df_combi, method="rf")
df_combi <- data.frame(diagnosis=testing$diagnosis,rf=training_pred_rf,gbm=training_pred_gbm,lda=training_pred_lda)
df_combi <- data.frame(diagnosis=training$diagnosis,rf=training_pred_rf,gbm=training_pred_gbm,lda=training_pred_lda)
model_final <- train(diagnosis~., data=df_combi, method="rf")
pred_final <- predict(model_final,pred_combi)
pred_final <- predict(model_final,df_combi)
accuracy(pred_final,testing$diagnosis)
pred_final <- predict(model_final,df_combi)
accuracy(pred_final,testing$diagnosis)
```
accuracy(pred_final,testing$diagnosis)
pred_combi <- data.frame(diagnosis=testing$diagnosis,rf=pred_rf, gbm=pred_gbm,lda=pred_lda)
pred_final <- predict(model_final,pred_combi)
accuracy(pred_final,testing$diagnosis)
install.pacakges("elasticnet")
install.packages("elasticnet")
install.packages("lubridate")
install.packages("forecast")
library(forecast)
url="https://d396qusza40orc.cloudfront.net/predmachlearn/gaData.csv"
dat = read.csv(url)
training = dat[year(dat$date) < 2012,]
testing = dat[(year(dat$date)) > 2011,]
tstrain = ts(training$visitsTumblr)
```
Fit a model using the bats() function in the forecast package to the training time series. Then forecast this model for the remaining time points. For how many of the testing points is the true value within the 95% prediction interval bounds?
```{r}
#install.packages("forecast")
library(forecast)
model_q4 <- bats(tstrain)
pred_q4 <- forecast(model_q4, level=95, nrow(testing))
sum(testing$visitsTumblr>pred_q4$lower &  testing$visitsTumblr<pred_q4$upper)/nrow(testing)
#install.packages("lubridate")
library(lubridate)  # For year() function below
url="https://d396qusza40orc.cloudfront.net/predmachlearn/gaData.csv"
dat = read.csv(url)
training = dat[year(dat$date) < 2012,]
testing = dat[(year(dat$date)) > 2011,]
tstrain = ts(training$visitsTumblr)
#install.packages("forecast")
library(forecast)
model_q4 <- bats(tstrain)
pred_q4 <- forecast(model_q4, level=95, nrow(testing))
sum(testing$visitsTumblr>pred_q4$lower &  testing$visitsTumblr<pred_q4$upper)/nrow(testing)
library(lubridate)  # For year() function below
url="https://d396qusza40orc.cloudfront.net/predmachlearn/gaData.csv"
#install.packages("lubridate")
library(lubridate)  # For year() function below
url="https://d396qusza40orc.cloudfront.net/predmachlearn/gaData.csv"
dat = read.csv(url)
training = dat[year(dat$date) < 2012,]
testing = dat[(year(dat$date)) > 2011,]
tstrain = ts(training$visitsTumblr)
#install.packages("lubridate")
library(lubridate)  # For year() function below
download.file(url,destfile="./data_q4.csv")
dat = read.csv("./data_q4.csv")
training = dat[year(dat$date) < 2012,]
testing = dat[(year(dat$date)) > 2011,]
tstrain = ts(training$visitsTumblr)
###Question 4
Load the data on the number of visitors to the instructors blog from here:
https://d396qusza40orc.cloudfront.net/predmachlearn/gaData.csv
Using the commands:
```{r}
#install.packages("lubridate")
library(lubridate)
url="http://d396qusza40orc.cloudfront.net/predmachlearn/gaData.csv"
download.file(url,destfile="./data_q4.csv")
dat = read.csv("./data_q4.csv")
training = dat[year(dat$date) < 2012,]
testing = dat[(year(dat$date)) > 2011,]
tstrain = ts(training$visitsTumblr)
```
Fit a model using the bats() function in the forecast package to the training time series. Then forecast this model for the remaining time points. For how many of the testing points is the true value within the 95% prediction interval bounds?
```{r}
#install.packages("forecast")
library(forecast)
model_q4 <- bats(tstrain)
pred_q4 <- forecast(model_q4, level=95, nrow(testing))
sum(testing$visitsTumblr>pred_q4$lower &  testing$visitsTumblr<pred_q4$upper)/nrow(testing)
```
